{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as lda\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.qda import QDA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as qda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Default.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"student\"] = df[\"student\"].astype('category')\n",
    "df[\"student_cat\"] = df[\"student\"].cat.codes\n",
    "df[\"default\"] = df[\"default\"].astype('category')\n",
    "df[\"default_cat\"] = df[\"default\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df = df.drop([\"default\",\"student\"],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "      <th>student_cat</th>\n",
       "      <th>default_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>919.588530</td>\n",
       "      <td>7491.558572</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>825.513331</td>\n",
       "      <td>24905.226578</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>808.667504</td>\n",
       "      <td>17600.451344</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1161.057854</td>\n",
       "      <td>37468.529288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>29275.268293</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>21871.073089</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1220.583753</td>\n",
       "      <td>13268.562221</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>237.045114</td>\n",
       "      <td>28251.695345</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>606.742343</td>\n",
       "      <td>44994.555849</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1112.968401</td>\n",
       "      <td>23810.174050</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>286.232560</td>\n",
       "      <td>45042.413036</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>50265.312354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>527.540184</td>\n",
       "      <td>17636.539617</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>485.936864</td>\n",
       "      <td>61566.106118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1095.072735</td>\n",
       "      <td>26464.631389</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>228.952550</td>\n",
       "      <td>50500.182198</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>954.261793</td>\n",
       "      <td>32457.509075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1055.956605</td>\n",
       "      <td>51317.883082</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>641.984389</td>\n",
       "      <td>30466.103257</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>773.211725</td>\n",
       "      <td>34353.314305</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>855.008523</td>\n",
       "      <td>25211.332161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>642.999739</td>\n",
       "      <td>41473.511801</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1454.863272</td>\n",
       "      <td>32189.094952</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>615.704277</td>\n",
       "      <td>39376.394619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1119.569353</td>\n",
       "      <td>16556.070205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>1294.500408</td>\n",
       "      <td>25687.326050</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>180.620128</td>\n",
       "      <td>20975.560495</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>755.432801</td>\n",
       "      <td>14455.865365</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>876.119027</td>\n",
       "      <td>37668.366788</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>933.332025</td>\n",
       "      <td>26051.398320</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>908.315934</td>\n",
       "      <td>21287.942487</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>218.417559</td>\n",
       "      <td>25401.133121</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>915.439827</td>\n",
       "      <td>16624.339111</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>2202.462395</td>\n",
       "      <td>47287.257108</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>173.249172</td>\n",
       "      <td>30697.245062</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>770.015741</td>\n",
       "      <td>13684.789952</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>739.418018</td>\n",
       "      <td>40656.951448</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>623.526119</td>\n",
       "      <td>59441.309981</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>506.625454</td>\n",
       "      <td>49861.003411</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>875.241640</td>\n",
       "      <td>52861.744197</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>842.949429</td>\n",
       "      <td>39957.127855</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>401.332674</td>\n",
       "      <td>15332.017833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>1092.906583</td>\n",
       "      <td>45479.466985</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>41740.686597</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>999.281112</td>\n",
       "      <td>20013.350644</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>372.379239</td>\n",
       "      <td>25374.899085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>658.799558</td>\n",
       "      <td>54802.078221</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>1111.647317</td>\n",
       "      <td>45490.682463</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>938.836241</td>\n",
       "      <td>56633.448744</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>172.412987</td>\n",
       "      <td>14955.941689</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>711.555020</td>\n",
       "      <td>52992.378914</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>757.962918</td>\n",
       "      <td>19660.721768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>845.411989</td>\n",
       "      <td>58636.156984</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1569.009053</td>\n",
       "      <td>36669.112365</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>200.922183</td>\n",
       "      <td>16862.952321</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           balance        income  student_cat  default_cat\n",
       "1       729.526495  44361.625074            0            0\n",
       "2       817.180407  12106.134700            1            0\n",
       "3      1073.549164  31767.138947            0            0\n",
       "4       529.250605  35704.493935            0            0\n",
       "5       785.655883  38463.495879            0            0\n",
       "6       919.588530   7491.558572            1            0\n",
       "7       825.513331  24905.226578            0            0\n",
       "8       808.667504  17600.451344            1            0\n",
       "9      1161.057854  37468.529288            0            0\n",
       "10        0.000000  29275.268293            0            0\n",
       "11        0.000000  21871.073089            1            0\n",
       "12     1220.583753  13268.562221            1            0\n",
       "13      237.045114  28251.695345            0            0\n",
       "14      606.742343  44994.555849            0            0\n",
       "15     1112.968401  23810.174050            0            0\n",
       "16      286.232560  45042.413036            0            0\n",
       "17        0.000000  50265.312354            0            0\n",
       "18      527.540184  17636.539617            1            0\n",
       "19      485.936864  61566.106118            0            0\n",
       "20     1095.072735  26464.631389            0            0\n",
       "21      228.952550  50500.182198            0            0\n",
       "22      954.261793  32457.509075            0            0\n",
       "23     1055.956605  51317.883082            0            0\n",
       "24      641.984389  30466.103257            0            0\n",
       "25      773.211725  34353.314305            0            0\n",
       "26      855.008523  25211.332161            0            0\n",
       "27      642.999739  41473.511801            0            0\n",
       "28     1454.863272  32189.094952            0            0\n",
       "29      615.704277  39376.394619            0            0\n",
       "30     1119.569353  16556.070205            1            0\n",
       "...            ...           ...          ...          ...\n",
       "9971   1294.500408  25687.326050            1            0\n",
       "9972    180.620128  20975.560495            1            0\n",
       "9973    755.432801  14455.865365            0            0\n",
       "9974    876.119027  37668.366788            0            0\n",
       "9975    933.332025  26051.398320            1            0\n",
       "9976    908.315934  21287.942487            0            0\n",
       "9977    218.417559  25401.133121            0            0\n",
       "9978    915.439827  16624.339111            1            0\n",
       "9979   2202.462395  47287.257108            0            1\n",
       "9980    173.249172  30697.245062            0            0\n",
       "9981    770.015741  13684.789952            1            0\n",
       "9982    739.418018  40656.951448            0            0\n",
       "9983    623.526119  59441.309981            0            0\n",
       "9984    506.625454  49861.003411            0            0\n",
       "9985    875.241640  52861.744197            0            0\n",
       "9986    842.949429  39957.127855            0            0\n",
       "9987    401.332674  15332.017833            1            0\n",
       "9988   1092.906583  45479.466985            0            0\n",
       "9989      0.000000  41740.686597            0            0\n",
       "9990    999.281112  20013.350644            1            0\n",
       "9991    372.379239  25374.899085            0            0\n",
       "9992    658.799558  54802.078221            0            0\n",
       "9993   1111.647317  45490.682463            0            0\n",
       "9994    938.836241  56633.448744            0            0\n",
       "9995    172.412987  14955.941689            1            0\n",
       "9996    711.555020  52992.378914            0            0\n",
       "9997    757.962918  19660.721768            0            0\n",
       "9998    845.411989  58636.156984            0            0\n",
       "9999   1569.009053  36669.112365            0            0\n",
       "10000   200.922183  16862.952321            1            0\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[\"default_cat\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df= df.drop([\"default_cat\"],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(df,y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train,y_train)\n",
    "predictions_nb = gnb.predict(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = lda()#store_covariance=True\n",
    "X_r2  = clf.fit(x_train, y_train).transform(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_r2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_lda = clf_fit.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pandas/core/ops.py:798: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = getattr(x, name)(y)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "invalid type comparison",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-3e7a1f037024>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     plt.scatter(X_r2[y == \"Yes\", 0], X_r2[y == \"No\", 1], alpha=.8, color=color,\n\u001b[0m\u001b[1;32m      7\u001b[0m                 label=target_name)\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'best'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshadow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscatterpoints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                 raise TypeError('Could not compare %s type with Series' %\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    798\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"invalid type comparison\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: invalid type comparison"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "colors = ['navy', 'turquoise']\n",
    "target_names = [\"Yes\",\"No\"]\n",
    "\n",
    "for color, i, target_name in zip(colors, [0, 1], target_names):\n",
    "    plt.scatter(X_r2[y == , 0], X_r2[y == \"No\", 1], alpha=.8, color=color,\n",
    "                label=target_name)\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('LDA of IRIS dataset')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_qda = qda()\n",
    "clf_qda_fit = clf_qda.fit(x_train,y_train)\n",
    "predictions_qda = clf_qda.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7715   28]\n",
      " [ 202   55]]\n",
      "\n",
      "TN = 7715\n",
      "FP = 28\n",
      "FN = 202\n",
      "TP = 55\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "confuse = confusion_matrix(y_train,predictions_nb)\n",
    "print(confuse)\n",
    "\n",
    "print(\"\\nTN =\",confuse[0][0])\n",
    "print(\"FP =\",confuse[0][1])\n",
    "print(\"FN =\",confuse[1][0])\n",
    "print(\"TP =\",confuse[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7728   15]\n",
      " [ 200   57]]\n",
      "\n",
      "TN = 7728\n",
      "FP = 15\n",
      "FN = 200\n",
      "TP = 57\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "confuse = confusion_matrix(y_train,predictions_lda)\n",
    "print(confuse)\n",
    "\n",
    "print(\"\\nTN =\",confuse[0][0])\n",
    "print(\"FP =\",confuse[0][1])\n",
    "print(\"FN =\",confuse[1][0])\n",
    "print(\"TP =\",confuse[1][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7725   18]\n",
      " [ 198   59]]\n",
      "\n",
      "TN = 7725\n",
      "FP = 18\n",
      "FN = 198\n",
      "TP = 59\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "confuse = confusion_matrix(y_train,predictions_qda)\n",
    "print(confuse)\n",
    "\n",
    "print(\"\\nTN =\",confuse[0][0])\n",
    "print(\"FP =\",confuse[0][1])\n",
    "print(\"FN =\",confuse[1][0])\n",
    "print(\"TP =\",confuse[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'priors': None, 'reg_param': 0.0, 'store_covariances': False, 'tol': 0.0001}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_qda_fit.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of classifier is: 0.975\n",
      "precision: 0.75\n",
      "recall: 0.25\n"
     ]
    }
   ],
   "source": [
    "#overall accuracy\n",
    "accuracy = (confuse[0][0] + confuse[1][1])/ len(y_test)\n",
    "print(\"accuracy of classifier is:\",accuracy)\n",
    "#precision is a measure of positive predictions negative or ratio of tp/overal p\n",
    "precision =  confuse[1][1]/(confuse[1][1]+confuse[0][1])\n",
    "print(\"precision:\",precision)\n",
    "#recall is proportion all true positive samples.\n",
    "recall = confuse[1][1]/(confuse[1][1]+confuse[1][0])\n",
    "print(\"recall:\",recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      1940\n",
      "          1       0.75      0.25      0.38        60\n",
      "\n",
      "avg / total       0.97      0.97      0.97      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.94      0.96      1940\n",
      "          1       0.28      0.78      0.41        60\n",
      "\n",
      "avg / total       0.97      0.93      0.95      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "probs_positive_class = clf_fit.predict_proba(x_test)[:, 1]\n",
    "probs_positive_class\n",
    "\n",
    "results = []\n",
    "for i in probs_positive_class:\n",
    "    if i > 0.1:\n",
    "        i = 1\n",
    "        results.append(i)    \n",
    "    else:\n",
    "        i = 0\n",
    "        results.append(i)\n",
    "#print(results)\n",
    "\n",
    "print(classification_report(y_test,results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1819  121]\n",
      " [  13   47]]\n",
      "\n",
      "TN = 1819\n",
      "FP = 121\n",
      "FN = 13\n",
      "TP = 47\n"
     ]
    }
   ],
   "source": [
    "confuse_new = confusion_matrix(y_test,results)\n",
    "print(confuse_new)\n",
    "\n",
    "print(\"\\nTN =\",confuse_new[0][0])\n",
    "print(\"FP =\",confuse_new[0][1])\n",
    "print(\"FN =\",confuse_new[1][0])\n",
    "print(\"TP =\",confuse_new[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:656: DeprecationWarning: The parameter 'store_covariances' is deprecated as of version 0.17 and will be removed in 0.19. The parameter is no longer necessary because the value is set via the estimator initialisation or set_params method.\n",
      "  \"set_params method.\", DeprecationWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:695: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:719: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:719: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:722: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n"
     ]
    }
   ],
   "source": [
    "# QDA\n",
    "qda = QDA()\n",
    "qda_fit = qda.fit(x_train, y_train, store_covariances=True)\n",
    "y_pred_qda = qda_fit.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1940    0]\n",
      " [  60    0]]\n",
      "\n",
      "TN = 1940\n",
      "FP = 0\n",
      "FN = 60\n",
      "TP = 0\n"
     ]
    }
   ],
   "source": [
    "confuse_qda = confusion_matrix(y_test,y_pred_qda)\n",
    "print(confuse_qda)\n",
    "\n",
    "print(\"\\nTN =\",confuse_qda[0][0])\n",
    "print(\"FP =\",confuse_qda[0][1])\n",
    "print(\"FN =\",confuse_qda[1][0])\n",
    "print(\"TP =\",confuse_qda[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      1940\n",
      "          1       0.00      0.00      0.00        60\n",
      "\n",
      "avg / total       0.94      0.97      0.96      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_qda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_qda = []\n",
    "probs_positive_class_qda = qda_fit.predict_proba(x_test)[:, 1]\n",
    "for i in probs_positive_class_qda:\n",
    "    if i > 0.2:\n",
    "        i = 1\n",
    "        results_qda.append(i)    \n",
    "    else:\n",
    "        i = 0\n",
    "        results_qda.append(i)\n",
    "#print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.97      0.97      1932\n",
      "          1       0.36      0.53      0.43        68\n",
      "\n",
      "avg / total       0.96      0.95      0.96      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,results_qda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot data\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import colors\n",
    "\n",
    "def plot_data(lda, X, y, y_pred, fig_index):\n",
    "    splot = plt.subplot(2, 2, fig_index)\n",
    "    if fig_index == 1:\n",
    "        plt.title('Linear Discriminant Analysis')\n",
    "        plt.ylabel('Data with fixed covariance')\n",
    "    elif fig_index == 2:\n",
    "        plt.title('Quadratic Discriminant Analysis')\n",
    "    elif fig_index == 3:\n",
    "        plt.ylabel('Data with varying covariances')\n",
    "\n",
    "    tp = (y_test == y_pred)  # True Positive\n",
    "    tp0, tp1 = tp[y_test == 0], tp[y_test == 1]\n",
    "    X0, X1 = x_test[y == 0], x_test[y == 1]\n",
    "    X0_tp, X0_fp = X0[tp0], X0[~tp0]\n",
    "    X1_tp, X1_fp = X1[tp1], X1[~tp1]\n",
    "    xmin, xmax = x_test[:, 0].min(), x_test[:, 0].max()\n",
    "    ymin, ymax = x_test[:, 1].min(), x_test[:, 1].max()\n",
    "\n",
    "    # class 0: dots\n",
    "    plt.plot(X0_tp[:, 0], X0_tp[:, 1], 'o', color='red')\n",
    "    plt.plot(X0_fp[:, 0], X0_fp[:, 1], '.', color='#990000')  # dark red\n",
    "\n",
    "    # class 1: dots\n",
    "    plt.plot(X1_tp[:, 0], X1_tp[:, 1], 'o', color='blue')\n",
    "    plt.plot(X1_fp[:, 0], X1_fp[:, 1], '.', color='#000099')  # dark blue\n",
    "\n",
    "    # class 0 and 1 : areas\n",
    "    nx, ny = 200, 100\n",
    "    x_min, x_max = plt.xlim()\n",
    "    y_min, y_max = plt.ylim()\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, nx),\n",
    "                         np.linspace(y_min, y_max, ny))\n",
    "    Z = lda.predict_proba(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z[:, 1].reshape(xx.shape)\n",
    "    plt.pcolormesh(xx, yy, Z, cmap='red_blue_classes',\n",
    "                   norm=colors.Normalize(0., 1.))\n",
    "    plt.contour(xx, yy, Z, [0.5], linewidths=2., colors='k')\n",
    "\n",
    "    # means\n",
    "    plt.plot(lda.means_[0][0], lda.means_[0][1],\n",
    "             'o', color='black', markersize=10)\n",
    "    plt.plot(lda.means_[1][0], lda.means_[1][1],\n",
    "             'o', color='black', markersize=10)\n",
    "\n",
    "    return splot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_data(lda,x_test,y_test,y_pred,fig_index=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "target_names = iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
